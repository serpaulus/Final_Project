{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7adbc44",
   "metadata": {},
   "source": [
    "# [Database options]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af616cbd",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa673d7",
   "metadata": {},
   "source": [
    "# Using AWS RDS, Spark, and Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c5e1c",
   "metadata": {},
   "source": [
    "## Set up Relational Database and connect to pgAdmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ceef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AWS Relational Database 16.7.2\n",
    "# Connecting AWS to pgAdmin 16.7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5f051",
   "metadata": {},
   "source": [
    "## CRUD with AWS - Changing database stored in AWS cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02e69d",
   "metadata": {},
   "source": [
    "## [In pgAdmin]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b97635",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE doctors (\n",
    "#  id INT PRIMARY KEY NOT NULL,\n",
    "#  speciality TEXT,\n",
    "#  taking_patients BOOLEAN\n",
    "# );\n",
    "# CREATE TABLE patients (\n",
    "#  id INT NOT NULL,\n",
    "#  doctor_id INT NOT NULL,\n",
    "#  health_status TEXT,\n",
    "#  PRIMARY KEY (id, doctor_id),\n",
    "#  FOREIGN KEY (doctor_id) REFERENCES doctors (id)\n",
    "# );\n",
    "\n",
    "# INSERT INTO doctors(id, speciality, taking_patients)\n",
    "# VALUES\n",
    "# (1, 'cardiology', TRUE),\n",
    "# (2, 'orthopedics', FALSE),\n",
    "# (3, 'pediatrics', TRUE);\n",
    "# INSERT INTO patients (id, doctor_id, health_status)\n",
    "# VALUES\n",
    "# (1, 2, 'healthy'),\n",
    "# (2, 3, 'sick'),\n",
    "# (3, 2, 'sick'),\n",
    "# (4, 1, 'healthy'),\n",
    "# (5, 1, 'sick');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0888c3f",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Read tables\n",
    "SELECT * FROM doctors;\n",
    "SELECT * FROM patients;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb405f6",
   "metadata": {},
   "source": [
    "### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd088c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Update rows\n",
    "UPDATE doctors\n",
    "SET taking_patients = FALSE\n",
    "WHERE id = 1;\n",
    "UPDATE patients\n",
    "SET health_status = 'healthy'\n",
    "WHERE id = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144e31a",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13dda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- Delete row\n",
    "DELETE FROM patients\n",
    "WHERE id = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1900de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files into bucket\n",
    "# 16.9.1 PySpark ETL Full example saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d115453",
   "metadata": {},
   "source": [
    " # PySpark ETL - using Google Colab and Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe8033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data with AWS S3 16.8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986cc03",
   "metadata": {},
   "source": [
    "## [In pgAdmin]\n",
    "### Create tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c2d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Create Active User Table in pdAdmin\n",
    "# CREATE TABLE active_user (\n",
    "#  id INT PRIMARY KEY NOT NULL,\n",
    "#  first_name TEXT,\n",
    "#  last_name TEXT,\n",
    "#  username TEXT\n",
    "# );\n",
    "\n",
    "# CREATE TABLE billing_info (\n",
    "#  billing_id INT PRIMARY KEY NOT NULL,\n",
    "#  street_address TEXT,\n",
    "#  state TEXT,\n",
    "#  username TEXT\n",
    "# );\n",
    "\n",
    "# CREATE TABLE payment_info (\n",
    "#  billing_id INT PRIMARY KEY NOT NULL,\n",
    "#  cc_encrypted TEXT\n",
    "# );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac49ff",
   "metadata": {},
   "source": [
    "## [In Google Colab]\n",
    "### PySpark - Imports, Drivers, Required Installs, environment variables, create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.0.3'\n",
    "spark_version = 'spark-3.0.3'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download postgres driver to allow Spark to interact with Posgres\n",
    "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Spark seesion with an additional option that adds the driver to Spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d223720",
   "metadata": {},
   "source": [
    "### PySpark ETL - EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from S3 Buckets\n",
    "from pyspark import SparkFiles\n",
    "url =\"https://kwporras-bucket.s3.amazonaws.com/user_data.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "user_data_df = spark.read.csv(SparkFiles.get(\"user_data.csv\"), sep=\",\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DataFrame\n",
    "user_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55055915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from S3 buckets\n",
    "url =\"https://kwporras-bucket.s3.amazonaws.com/user_payment.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "user_payment_df = spark.read.csv(SparkFiles.get(\"user_payment.csv\"), sep=\",\", header=True, inferSchema=True)\n",
    "\n",
    "# Show DataFrame\n",
    "user_payment_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bab602",
   "metadata": {},
   "source": [
    "### PySpark ETL - TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two DataFrame\n",
    "joined_df= user_data_df.join(user_payment_df, on=\"username\", how=\"inner\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f87c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "dropna_df = joined_df.dropna()\n",
    "dropna_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd103c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a sql function to use columns\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter for only columns with active users\n",
    "cleaned_df = dropna_df.filter(col(\"active_user\") == True)\n",
    "cleaned_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user dataframe to match active_user table\n",
    "clean_user_df = cleaned_df.select([\"id\", \"first_name\", \"last_name\", \"username\"])\n",
    "clean_user_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57756dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user dataframe to match billing_info table\n",
    "clean_billing_df = cleaned_df.select([\"billing_id\", \"street_address\", \"State\", \"username\"])\n",
    "clean_billing_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user dataframe to match payment_info table\n",
    "clean_payment_df = cleaned_df.select([\"billing_id\", \"cc_encrypted\"])\n",
    "clean_payment_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107baf6f",
   "metadata": {},
   "source": [
    "### PySpark ETL - LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe99e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store environmental variable\n",
    "from getpass import getpass\n",
    "password = getpass('Enter database password')\n",
    "# Configure settings for RDS\n",
    "mode = \"append\"\n",
    "jdbc_url=\"jdbc:postgresql://dataviz.czshayekq14i.us-east-2.rds.amazonaws.com:5432/my_data_class_db\"\n",
    "config = {\"user\":\"postgres\",\n",
    "          \"password\": password,\n",
    "          \"driver\":\"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DataFrame to active_user table in RDS\n",
    "clean_user_df.write.jdbc(url=jdbc_url, table='active_user', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to billing_info table in RDS\n",
    "clean_billing_df.write.jdbc(url=jdbc_url, table='billing_info', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acbd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe to payment_info table in RDS\n",
    "clean_payment_df.write.jdbc(url=jdbc_url, table='payment_info', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f318b",
   "metadata": {},
   "source": [
    "## [In pgAdmin]\n",
    "### -- Query database to check successful upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b68400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT * FROM active_user;\n",
    "# SELECT * FROM billing_info;\n",
    "# SELECT * FROM payment_info;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9f753",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9a5ba",
   "metadata": {},
   "source": [
    "# Alternative - Increase user accessiblilty to Database by avoiding postgreSQL\n",
    "### Use sqlalchemy and sqlite  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy import extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up the Database engine for the Flask application to allow access to the SQLite database\n",
    "engine = create_engine(\"sqlite:///hawaii.sqlite\")\n",
    "\n",
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10448d",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b892251d",
   "metadata": {},
   "source": [
    "# Connecting Pandas and SQL 8.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7447e96",
   "metadata": {},
   "source": [
    "### Create a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure a database in create in SQL covered above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e06c2b",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cbf259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54999ec5",
   "metadata": {},
   "source": [
    "### Create the Database Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"postgresql://[user]:[password]@[location]:[port]/[database]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Practice - hide password in a config.py file and play config.py in .gitignore file\n",
    "db_password = 'YOUR_PASSWORD_HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local server connection string\n",
    "db_string = f\"postgresql://postgres:{db_password}{db_password}@housing-prices.ctpruadwlamv.us-east-2.rds.amazonaws.com:5432/housing-prices\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e47254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database engine\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49b7ba",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
